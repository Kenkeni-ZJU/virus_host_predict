{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import timeit\n",
    "from collections import defaultdict, Counter\n",
    "from pathlib import Path\n",
    "from Bio import SeqIO\n",
    "import sys\n",
    "lib_dir = '../mylibs'\n",
    "if lib_dir not in sys.path:\n",
    "    sys.path.append(lib_dir)\n",
    "    \n",
    "import vhdb as vhdb\n",
    "import features_predict as fp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The input dataset files in ../inputs \n",
    "1. Bacteria_DNA.csv \n",
    "2. Euk_subsets.csv\n",
    "3. Euk_all.csv\n",
    "4. Euk_RNA.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the input files to train and test\n",
    "1. input/ datasets  \n",
    "2. VHDB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67 datasets : ('Alteromonadales', 'order', 'Gammaproteobacteria', 'class', 'DNA')\n",
      "9199 viruses and 3006 hosts\n",
      "Results will be saved in: ../results/Bacteria_DNA_results.csv \n"
     ]
    }
   ],
   "source": [
    "# Input file  \n",
    "subsetfile = '../inputs/Bacteria_DNA.csv'\n",
    "label_info = pd.read_csv(subsetfile)\n",
    "subsets = label_info.apply(tuple, axis=1).tolist()\n",
    "print(f'{len(subsets)} datasets : {subsets[0]}')\n",
    "\n",
    "vhdbfile = '../inputs/VHDB_25_1_2019.p'\n",
    "with open(vhdbfile, 'rb') as f:\n",
    "    V_H = pickle.load( f)\n",
    "hosts = V_H.hosts\n",
    "viruses = V_H.viruses\n",
    "print (f'{len(viruses)} viruses and {len(hosts)} hosts')\n",
    "\n",
    "\n",
    "# Output file for the results\n",
    "results_file = f'../results/{Path(subsetfile).stem}_results.csv '\n",
    "print (f'Results will be saved in: {results_file}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the different features to be tested and corresponding lists:\n",
    "1. Filepaths and extensions\n",
    "2. k-mer lengths\n",
    "3. Lookup for symbols used in sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "baltimore = 'all'\n",
    "\n",
    "# Everthing in the same order as the features list\n",
    "\n",
    "feature_list = ['DNA','AA','PC','Domains']\n",
    "# filepath for the fasta, faa and domain files\n",
    "filepaths = [   '/home4/youn01f/Desktop/workspace/newData/fasta',\n",
    "                '/home4/youn01f/Desktop/workspace/newData/faa',\n",
    "                 '/home4/youn01f/Desktop/workspace/newData/faa',\n",
    "                '/home4/youn01f/Desktop/workspace/newData/pfs']\n",
    "file_exts = ['fasta','fasta','fasta','pfs']#,'fasta',fasta]\n",
    "\n",
    "# A list of kmers for each feature set to be tested\n",
    "kmer_lists = [[1,2,3,4,5,6,7,8,9], # dna \n",
    "              [1,2,3,4],           # aa\n",
    "              [1,2,3,4,5,6] ,      #pc\n",
    "             [0]]                  #domains\n",
    "\n",
    "# symbol dictionaries \n",
    "na_dict = {'mod':4,'a':0,'c':1,'g':2,'t':3}\n",
    "aa_dict = {'mod':20 ,'A':0,'C':1,'D':2,'E':3,'F':4,'G':5,'H':6,'I':7,'K':8,'L':9,'M':10,'N':11,\n",
    "              'P':12,'Q':13,'R':14,'S':15,'T':16,'V':17,'W':18,'Y':19}\n",
    "pc_dict = {'mod':7, 'C':0,\n",
    "            'A':1,'G':1,'V':1,\n",
    "           'I':2,'L':2,'F':2,'P':2,\n",
    "           'M':3,'S':3,'T':3,'Y':3,\n",
    "           'H':4,'N':4,'Q':4,'W':4,\n",
    "           'R':5,'K':5,\n",
    "           'D':6,'E':6}\n",
    "symbol_dicts = [ na_dict,aa_dict,pc_dict, {}]\n",
    "\n",
    "classifiers = ['SVM_lin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " size of training 74 and test set   20\n",
      "Bacteroidetes phylum Bacteria superkingdom DNA\n",
      "len ds 74\n",
      "getting DNA sequences from /home4/youn01f/Desktop/workspace/newData/fasta\n",
      "viruses number of missing files 0\n",
      "20\n",
      "X_training:Extacting  features  of length  1  from   74 sequences\n",
      "X_test: Extacting  features  of length  1  from   20 sequences\n",
      "X train: (74, 4),X test: (20, 4), y train: (74,),y_test: (20,)\n",
      "{'AUC': 0.958, 'N in class': 47, 'Features': 'DNA', 'k': 1}\n",
      "getting AA sequences from /home4/youn01f/Desktop/workspace/newData/faa\n",
      "viruses number of missing files 0\n",
      "20\n",
      "X_training:Extacting  features  of length  1  from   74 sequences\n",
      "X_test: Extacting  features  of length  1  from   20 sequences\n",
      "X train: (74, 20),X test: (20, 20), y train: (74,),y_test: (20,)\n",
      "{'AUC': 1.0, 'N in class': 47, 'Features': 'AA', 'k': 1}\n",
      "getting PC sequences from /home4/youn01f/Desktop/workspace/newData/faa\n",
      "viruses number of missing files 0\n",
      "20\n",
      "X_training:Extacting  features  of length  1  from   74 sequences\n",
      "X_test: Extacting  features  of length  1  from   20 sequences\n",
      "X train: (74, 7),X test: (20, 7), y train: (74,),y_test: (20,)\n",
      "{'AUC': 0.927, 'N in class': 47, 'Features': 'PC', 'k': 1}\n",
      "getting Domains sequences from /home4/youn01f/Desktop/workspace/newData/pfs\n",
      "viruses number of missing files 0\n",
      "20\n",
      "X_training:Extacting  features  of length  0  from   74 sequences\n",
      "X_test: Extacting  features  of length  0  from   20 sequences\n",
      "X train: (74, 654),X test: (20, 654), y train: (74,),y_test: (20,)\n",
      "{'AUC': 0.99, 'N in class': 47, 'Features': 'Domains', 'k': 0}\n"
     ]
    }
   ],
   "source": [
    "features = ['DNA','AA','PC','Domains']\n",
    "for subset in subsets[-1:]:\n",
    "    class_data,n = fp.get_class_lists(subset,viruses,hosts)\n",
    "    datasets = fp.split_data(viruses,class_data,n)\n",
    "    (label,label_tax,pool,pool_tax,baltimore) = subset\n",
    "    print  (label,label_tax,pool,pool_tax,baltimore)\n",
    "    print('len ds',len(datasets['training']))\n",
    "    for feature in features:\n",
    "        \n",
    "        index = feature_list.index(feature)\n",
    "        kmers = kmer_lists[index]\n",
    "        filepath = filepaths[index]\n",
    "        symbol_dict = symbol_dicts[index]\n",
    "        ext = file_exts[index]\n",
    "        \n",
    "        if features != 'PC': #PC same sequence as for AA\n",
    "            filepath = filepaths[index]\n",
    "            print ( f'getting {feature} sequences from {filepath}')\n",
    "            sequences = fp.get_sequences(filepath,datasets,ext)\n",
    "            print (len(sequences['test']))\n",
    "        for k in kmers: \n",
    "            x_train,x_test,y_train,y_test = fp.get_feature_matrices(sequences,datasets,label,k,symbol_dict)\n",
    "            print (f'X train: {np.shape(x_train)},X test: {np.shape(x_test)}, y train: {np.shape(y_train)},y_test: {np.shape(y_test)}')\n",
    "            results = fp.test_prediction(x_train,x_test,y_train,y_test)\n",
    "            results.update ({'N in class': n, 'Features':feature, 'k':k})\n",
    "            print(results)\n",
    "            fp.results2CSV (results,subset, results_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
