{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import defaultdict, Counter\n",
    "import csv\n",
    "from pathlib import Path\n",
    "import sys\n",
    "lib_dir = '../mylibs'\n",
    "if lib_dir not in sys.path:\n",
    "    sys.path.append(lib_dir)\n",
    "    \n",
    "import vhdb as vhdb\n",
    "import features_predict as fp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the input file with datasets to train and test and VHDB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 datasets : ('Bacteroidetes', 'phylum', 'Bacteria', 'kingdom', 'DNA', 'Siphoviridae')\n",
      "9199 viruses and 3006 hosts\n",
      "Results will be saved in: ../results/Bact_holdout_results.csv\n"
     ]
    }
   ],
   "source": [
    "# Input file  \n",
    "subsetfile = '../inputs/Bact_holdout.csv'\n",
    "label_info = pd.read_csv(subsetfile)\n",
    "subsets = label_info.apply(tuple, axis=1).tolist()\n",
    "print(f'{len(subsets)} datasets : {subsets[0]}')\n",
    "\n",
    "vhdbfile = '../inputs/VHDB_25_1_2019.p'\n",
    "with open(vhdbfile, 'rb') as f:\n",
    "    V_H = pickle.load( f)\n",
    "hosts = V_H.hosts\n",
    "viruses = V_H.viruses\n",
    "print (f'{len(viruses)} viruses and {len(hosts)} hosts')\n",
    "\n",
    "\n",
    "# Output file for the results\n",
    "out_file = Path(subsetfile).stem \n",
    "print (f'Results will be saved in: ../results/{out_file}_results.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the different features to be tested and corresponding lists:\n",
    "1. Filepaths and extensions\n",
    "2. k-mer lengths\n",
    "3. Lookup for symbols used in sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "baltimore = 'all' # default\n",
    "\n",
    "# Everthing in the same order as the features list\n",
    "features = ['DNA','AA','PC','Domains']\n",
    "\n",
    "filepath for the fasta, faa and domain files\n",
    "filepaths = ['../data/fasta','../data/faa','../data/faa','../data/pfs']\n",
    "file_exts = ['fasta','fasta','fasta','pfs']\n",
    "\n",
    "# A list of kmers for each feature set to be tested\n",
    "kmer_lists = [\n",
    "              [2,6,9], # dna \n",
    "              [3,4], # aa\n",
    "              [5,6] ,    #pc\n",
    "              [0]] #domains\n",
    "\n",
    "\n",
    "# symbol dictionaries \n",
    "na_dict = {'mod':4,'a':0,'c':1,'g':2,'t':3}\n",
    "aa_dict = {'mod':20 ,'A':0,'C':1,'D':2,'E':3,'F':4,'G':5,'H':6,'I':7,'K':8,'L':9,'M':10,'N':11,\n",
    "              'P':12,'Q':13,'R':14,'S':15,'T':16,'V':17,'W':18,'Y':19}\n",
    "pc_dict = {'mod':7, 'C':0,\n",
    "            'A':1,'G':1,'V':1,\n",
    "           'I':2,'L':2,'F':2,'P':2,\n",
    "           'M':3,'S':3,'T':3,'Y':3,\n",
    "           'H':4,'N':4,'Q':4,'W':4,\n",
    "           'R':5,'K':5,\n",
    "           'D':6,'E':6}\n",
    "symbol_dicts = [ na_dict,aa_dict,pc_dict,{}]\n",
    "\n",
    "classifiers = ['SVM_lin']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alter get_class_lists for holdout classifier. \n",
    "Training data - everything but holdout viruse holdout virus group\n",
    "Test data - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_lists_ho(subset,viruses,hosts):\n",
    "    \n",
    "    (label,label_tax,pool,pool_tax,balt,v_holdout) = subset\n",
    "    data_lists = {'training':[[],[]],'test':[[],[]]}\n",
    "    # Get a list of all the viruses in the labelled class and the rest of the pool\n",
    "    baltimore = 'NA'  # all slasses (except satallites)\n",
    "    for v, vd in viruses.items() :\n",
    "        if  baltimore in vd['class']: \n",
    "            \n",
    "            if  vd['family']!= v_holdout:\n",
    "                ds_name ='training'\n",
    "            else:\n",
    "                ds_name = 'test'\n",
    "            \n",
    "            host_labels = [hosts[h][label_tax] for h in vd['hosts'] if hosts[h][pool_tax] == pool]    \n",
    "            if len(host_labels) > 0:\n",
    "                if label in host_labels:\n",
    "                    data_lists[ds_name][0].append ((v,label))\n",
    "                else:\n",
    "                    data_lists[ds_name][1].append ((v,'Other'))    \n",
    "                                                    \n",
    "    \n",
    " # Keep all the viruses in the holdout set as test data. they will not be same size   \n",
    "    datasets = {'training':{},'test':{}}\n",
    "    nmax = {'training':400,'test':50}\n",
    "    for k,data_list in data_lists.items():\n",
    "        datas =[]\n",
    "        n = min (len(data_list[0]),len(data_list[1]),nmax[k])\n",
    "        # randomly choose n viruses from both classes\n",
    "        for clss in data_list: \n",
    "            data = (random.sample(clss, n))\n",
    "            datas.extend(data)\n",
    "            \n",
    "       # shuffle together\n",
    "        random.shuffle(datas)\n",
    "        \n",
    "        for v,l in datas:\n",
    "            datasets [k][v]= {'label':l, 'refseqs':viruses[v]['refseqs']}\n",
    "    ntrain = (len(datasets['training']))\n",
    "    ntest = (len(datasets['test']))\n",
    "   \n",
    "    return datasets,ntrain,ntest\n",
    "\n",
    "def get_class_lists(subset,viruses,hosts):\n",
    "# returns two list of viruses one for each  positive class and negative class    \n",
    "    (label,label_tax,pool,pool_tax,baltimore,v_ho) = subset\n",
    "    \n",
    "    if baltimore =='all':\n",
    "        baltimore = 'NA'  # all classes  contain either 'DNA' or 'RNA'\n",
    "    \n",
    "    pos_neg =  [[],[]]\n",
    "    # Get 2 lists of all the viruses in the labelled class and the rest of the pool\n",
    "    for v, vd in viruses.items() :\n",
    "        if baltimore in vd['class']:\n",
    "            \n",
    "            host_labels = [hosts[h][label_tax] for h in vd['hosts'] if hosts[h][pool_tax] == pool]\n",
    "            \n",
    "            if len(host_labels) > 0:\n",
    "                if label in host_labels:\n",
    "                    pos_neg[0].append ((v,label))\n",
    "                else:\n",
    "                    pos_neg[1].append((v,'Other'))    \n",
    "                         \n",
    "    # Get a random sample for each class of size n , the size of smallest class \n",
    "    #restrict to 400\n",
    "    n = min(len(pos_neg[0]),len(pos_neg[1]),400)\n",
    "   # n=6 # test \n",
    "    datas =  []\n",
    "    random.seed(10)\n",
    "    for clss in pos_neg:\n",
    "        data = (random.sample(clss, n))\n",
    "        datas.append(data)\n",
    "    \n",
    "    #split into training and test sets     \n",
    "    split = 0.75 \n",
    "    trn_tst_lst =  [[],[]]  #2 lists for training and test viruses\n",
    "    \n",
    "    for viruslist in datas:\n",
    "        for i in range(n):\n",
    "            if random.random() < split:\n",
    "                trn_tst_lst[0].append(viruslist[i]) \n",
    "            else:\n",
    "                trn_tst_lst[1].append(viruslist[i]) \n",
    "  # Convert to dataset dictionaries\n",
    "    datadicts = {'training':{},'test':{}}\n",
    "    ds = datadicts.keys()\n",
    "    for i,lst in enumerate(trn_tst_lst):\n",
    "        random.shuffle(lst)\n",
    "        k = list(ds)[i]\n",
    "        for v,l in lst:\n",
    "            datadicts [k][v]= {'label':l, 'refseqs':viruses[v]['refseqs']}\n",
    "        ntrain  =len(datadicts['training'])\n",
    "        ntest = len(datadicts['test'])\n",
    "    \n",
    "    return (datadicts,ntrain,ntest)\n",
    "     \n",
    "\n",
    "\n",
    "def results2CSV(results,subset, csvfile):\n",
    "    (label,label_tax,pool,pool_tax,balt,v_holdout,t_g) = subset\n",
    "    #results = { k : round(v, 3) for k,v in results.items()}\n",
    "    results['positive label'] = label\n",
    "    results['label tax group']= label_tax\n",
    "    results['pool label']= pool\n",
    "    results['pool tax group']= pool_tax\n",
    "    results['Baltimore'] = balt\n",
    "    results['virus holdout group'] = v_holdout\n",
    "    results['training group']= t_g\n",
    "    fieldnames = ['positive label','label tax group','pool label','pool tax group',\n",
    "                          'Baltimore','virus holdout group','training group', 'N in class' , \n",
    "                          'Features','k','AUC' ]\n",
    "    if os.path.isfile(csvfile):\n",
    "        with open(csvfile, 'a') as csvfile:\n",
    "            #fieldnames = ['positive label','label tax group','pool label','pool tax group','Baltimore','virus holdout group','training group', 'N in class' , 'Features','k','AUC','accuracy', 'specificity','sensitivity', 'TN/FP/FN/TP' ]\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "            writer.writerow(results) \n",
    "    else:\n",
    "        with open(csvfile, 'w') as csvfile:\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "            writer.writeheader()\n",
    "            writer.writerow(results)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_dataset(subset,datasets,n,results_file): \n",
    "    (label,label_tax,pool,pool_tax,balt,v_holdout,t_g) = subset\n",
    "    print ('********   ', t_g , label , v_holdout)\n",
    "    for feature in features:\n",
    "        index = features.index(feature)\n",
    "        kmers = kmer_lists[index]\n",
    "        filepath = filepaths[index]\n",
    "        symbol_dict = symbol_dicts[index]\n",
    "        ext = file_exts[index]\n",
    "        \n",
    "\n",
    "        if features != 'PC': #PC same sequence as for AA\n",
    "            filepath = filepaths[index]\n",
    "            sequences = fp.get_sequences(filepath,datasets,ext)\n",
    "            \n",
    "            \n",
    "        for k in kmers:\n",
    "            # get feature matrix , test prediction and write results to CSV file\n",
    "            print ('-------  ',feature,k)\n",
    "            x_train,x_test,y_train,y_test = fp.get_feature_matrices(sequences,datasets,label,k,symbol_dict)\n",
    "            print (f'------------ X train: {np.shape(x_train)},X test: {np.shape(x_test)}, y train: {np.shape(y_train)},y_test: {np.shape(y_test)}')\n",
    "            results = fp.test_prediction(x_train,x_test,y_train,y_test)\n",
    "            results.update ({'N in class': n, 'Features':feature, 'k':k})\n",
    "            print(results)\n",
    "            results2CSV (results,subset, results_file)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main loop\n",
    "#### For each dataset, run inner loop to train and test  all feature sets  as both normal and holdout classifiers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** ('Bacteroidetes', 'phylum', 'Bacteria', 'kingdom', 'DNA', 'Siphoviridae')\n",
      " ho training v 50 , test v 44\n",
      "********    holdout Bacteroidetes Siphoviridae\n",
      "viruses number of missing files 0\n",
      "-------   DNA 2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-c9ea8d0b5a3c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#     # for holdout data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdatasets_ho\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_class_lists_ho\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mviruses\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhosts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtest_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'holdout'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdatasets_ho\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'temp.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m#for all data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-31-381869e0ecfe>\u001b[0m in \u001b[0;36mtest_dataset\u001b[0;34m(subset, datasets, n, results_file)\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0;31m# get feature matrix , test prediction and write results to CSV file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'-------  '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_matrices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequences\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msymbol_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34mf'------------ X train: {np.shape(x_train)},X test: {np.shape(x_test)}, y train: {np.shape(y_train)},y_test: {np.shape(y_test)}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/workspace/virus_host_predict/mylibs/features_predict.py\u001b[0m in \u001b[0;36mget_feature_matrices\u001b[0;34m(sequences, datasets, label, k, symbol_dict)\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# domainsdom_list = list({dom for s in sequence.values() for dom in s})\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0msymbol_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mdom\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msequence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msequences\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msequence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdom\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_kmers\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msequences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'training'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msymbol_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m     \u001b[0mY_train\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mget_labels\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseq_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'training'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/workspace/virus_host_predict/mylibs/features_predict.py\u001b[0m in \u001b[0;36mextract_kmers\u001b[0;34m(sequences, k, symbol_dict)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msequences\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m             \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_word_frequ\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_len\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msymbol_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m             \u001b[0mseq_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;31m# normalise for length of genome(s)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/workspace/virus_host_predict/mylibs/features_predict.py\u001b[0m in \u001b[0;36mget_word_frequ\u001b[0;34m(sequence, k, vocab_len, symbol_dict)\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0;31m# If this for DNA/RNA then add the k-mers complinent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msymbol_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mod'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m                 \u001b[0mword_freqs\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpatternToNumber\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompliment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msymbol_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mword_freqs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for subset in subsets:\n",
    "    print('*****',subset)\n",
    "#     # for holdout data  \n",
    "    datasets_ho,n1,n2 = get_class_lists_ho (subset,viruses,hosts)\n",
    "    test_dataset((*subset,'holdout'),datasets_ho,n1,'temp.txt')\n",
    "    \n",
    "    #for all data\n",
    "    datasets_all,ntrain,n_ho = get_class_lists(subset,viruses,hosts)\n",
    "    test_dataset((*subset,'all'), datasets_all,ntrain,'temp.txt')\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
